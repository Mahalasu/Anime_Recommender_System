{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 15:13:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('featuren_engineering').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- members: integer (nullable = true)\n",
      " |-- japanese_title: string (nullable = true)\n",
      " |-- aired: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- aired_from: string (nullable = true)\n",
      " |-- aired_to: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anime_df = spark.read.csv('../data/parsed_anime.csv', header=True, inferSchema=True)\n",
    "anime_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-hot encode genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "genre_df = anime_df.withColumn('genre_item', explode(split(col('genre'), '[,]'))).withColumn('genre_item', trim(col('genre_item')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+\n",
      "|anime_id|  genre_item|\n",
      "+--------+------------+\n",
      "|   32281|       Drama|\n",
      "|   32281|     Romance|\n",
      "|   32281|      School|\n",
      "|   32281|Supernatural|\n",
      "|    5114|      Action|\n",
      "|    5114|   Adventure|\n",
      "|    5114|       Drama|\n",
      "|    5114|     Fantasy|\n",
      "|    5114|       Magic|\n",
      "|    5114|    Military|\n",
      "+--------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_df.select(['anime_id', 'genre_item']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_indexer = StringIndexer(inputCol='genre_item', outputCol='genre_index')\n",
    "genre_indexd_df = string_indexer.fit(genre_df).transform(genre_df).withColumn('genre_index', col('genre_index').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|anime_id|  genre_item|genre_index|\n",
      "+--------+------------+-----------+\n",
      "|   32281|       Drama|          5|\n",
      "|   32281|     Romance|          8|\n",
      "|   32281|      School|          9|\n",
      "|   32281|Supernatural|         12|\n",
      "|    5114|      Action|          1|\n",
      "|    5114|   Adventure|          2|\n",
      "|    5114|       Drama|          5|\n",
      "|    5114|     Fantasy|          3|\n",
      "|    5114|       Magic|         16|\n",
      "|    5114|    Military|         23|\n",
      "+--------+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_indexd_df[['anime_id', 'genre_item', 'genre_index']].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|anime_id|       genre_indexes|\n",
      "+--------+--------------------+\n",
      "|       1| [1, 2, 0, 5, 4, 25]|\n",
      "|       5|   [1, 5, 21, 4, 25]|\n",
      "|       6|           [1, 0, 4]|\n",
      "|       7|[1, 5, 16, 21, 32...|\n",
      "|       8|       [2, 3, 6, 12]|\n",
      "|      15|       [1, 0, 6, 20]|\n",
      "|      16|       [0, 5, 40, 8]|\n",
      "|      17|      [0, 6, 10, 20]|\n",
      "|      18|  [1, 37, 5, 19, 20]|\n",
      "|      19|[5, 26, 21, 32, 3...|\n",
      "+--------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_multihot_df = genre_indexd_df.groupby('anime_id').agg(collect_list('genre_index').alias('genre_indexes'))\n",
    "pre_multihot_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_genre_index = genre_indexd_df.agg(max(col('genre_index'))).head()['max(genre_index)']\n",
    "max_genre_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@udf(returnType='array<int>')\n",
    "def multihot_list(l, max_index):\n",
    "    fill = np.zeros(max_index + 1, dtype=np.int32)\n",
    "    for i in l:\n",
    "        fill[i] = 1\n",
    "    return fill.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multihot_df = pre_multihot_df.withColumn(\n",
    "    'genre_multihot',\n",
    "    multihot_list(col('genre_indexes'), lit(max_genre_index))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- genre_indexes: array (nullable = false)\n",
      " |    |-- element: integer (containsNull = false)\n",
      " |-- genre_multihot: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multihot_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|anime_id|       genre_indexes|      genre_multihot|\n",
      "+--------+--------------------+--------------------+\n",
      "|       1| [1, 2, 0, 5, 4, 25]|[1, 1, 1, 0, 1, 1...|\n",
      "|       5|   [1, 5, 21, 4, 25]|[0, 1, 0, 0, 1, 1...|\n",
      "|       6|           [1, 0, 4]|[1, 1, 0, 0, 1, 0...|\n",
      "|       7|[1, 5, 16, 21, 32...|[0, 1, 0, 0, 0, 1...|\n",
      "|       8|       [2, 3, 6, 12]|[0, 0, 1, 1, 0, 0...|\n",
      "|      15|       [1, 0, 6, 20]|[1, 1, 0, 0, 0, 0...|\n",
      "|      16|       [0, 5, 40, 8]|[1, 0, 0, 0, 0, 1...|\n",
      "|      17|      [0, 6, 10, 20]|[1, 0, 0, 0, 0, 0...|\n",
      "|      18|  [1, 37, 5, 19, 20]|[0, 1, 0, 0, 0, 1...|\n",
      "|      19|[5, 26, 21, 32, 3...|[0, 0, 0, 0, 0, 1...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multihot_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Rating Min-Max Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv('../data/rating.csv', header=True, inferSchema=True).filter(col('rating') > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_rating_df = rating_df.groupby('anime_id').agg(mean('rating').alias('ave_rating'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|anime_id|       ave_rating|\n",
      "+--------+-----------------+\n",
      "|   24171|7.386666666666667|\n",
      "|    9465|8.098352214212152|\n",
      "|   17679|7.293103448275862|\n",
      "|    1829|7.341757827235005|\n",
      "|    8086|7.939071817474721|\n",
      "|   17389|8.601839684625492|\n",
      "|   22097| 8.13076923076923|\n",
      "|   30654|8.687342833193629|\n",
      "|    5300|8.694010416666666|\n",
      "|    6336|8.497902097902099|\n",
      "+--------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ave_rating_df = rating_df.groupby('anime_id').agg(mean('rating').alias('ave_rating'))\n",
    "ave_rating_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['ave_rating'], outputCol='ave_rating_vec')\n",
    "ave_rating_scaler = MinMaxScaler(inputCol='ave_rating_vec', outputCol='ave_rating_scaled')\n",
    "pipeline = Pipeline(stages=[vec_assembler, ave_rating_scaler])\n",
    "\n",
    "rating_scaled_df = pipeline.fit(ave_rating_df).transform(ave_rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- ave_rating: double (nullable = true)\n",
      " |-- ave_rating_vec: vector (nullable = true)\n",
      " |-- ave_rating_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_scaled_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-------------------+--------------------+\n",
      "|anime_id|       ave_rating|     ave_rating_vec|   ave_rating_scaled|\n",
      "+--------+-----------------+-------------------+--------------------+\n",
      "|   24171|7.386666666666667|[7.386666666666667]|[0.7096296296296296]|\n",
      "|    9465|8.098352214212152|[8.098352214212152]| [0.788705801579128]|\n",
      "|   17679|7.293103448275862|[7.293103448275862]|[0.6992337164750958]|\n",
      "|    1829|7.341757827235005|[7.341757827235005]|[0.7046397585816672]|\n",
      "|    8086|7.939071817474721|[7.939071817474721]|[0.7710079797194134]|\n",
      "|   17389|8.601839684625492|[8.601839684625492]|[0.8446488538472768]|\n",
      "|   22097| 8.13076923076923| [8.13076923076923]|[0.7923076923076922]|\n",
      "|   30654|8.687342833193629|[8.687342833193629]|[0.8541492036881809]|\n",
      "|    5300|8.694010416666666|[8.694010416666666]|[0.8548900462962962]|\n",
      "|    6336|8.497902097902099|[8.497902097902099]|[0.8331002331002332]|\n",
      "+--------+-----------------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_scaled_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType='float')\n",
    "def unwrap_list(rating):\n",
    "    return rating.toArray().tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "|anime_id|       ave_rating|     ave_rating_vec|   ave_rating_scaled|ave_rating_minmax|\n",
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "|   24171|7.386666666666667|[7.386666666666667]|[0.7096296296296296]|       0.70962965|\n",
      "|    9465|8.098352214212152|[8.098352214212152]| [0.788705801579128]|        0.7887058|\n",
      "|   17679|7.293103448275862|[7.293103448275862]|[0.6992337164750958]|        0.6992337|\n",
      "|    1829|7.341757827235005|[7.341757827235005]|[0.7046397585816672]|       0.70463973|\n",
      "|    8086|7.939071817474721|[7.939071817474721]|[0.7710079797194134]|       0.77100796|\n",
      "|   17389|8.601839684625492|[8.601839684625492]|[0.8446488538472768]|       0.84464884|\n",
      "|   22097| 8.13076923076923| [8.13076923076923]|[0.7923076923076922]|        0.7923077|\n",
      "|   30654|8.687342833193629|[8.687342833193629]|[0.8541492036881809]|        0.8541492|\n",
      "|    5300|8.694010416666666|[8.694010416666666]|[0.8548900462962962]|       0.85489005|\n",
      "|    6336|8.497902097902099|[8.497902097902099]|[0.8331002331002332]|       0.83310026|\n",
      "+--------+-----------------+-------------------+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_scaled_df = rating_scaled_df.withColumn('ave_rating_minmax', unwrap_list(col('ave_rating_scaled')))\n",
    "rating_scaled_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- episodes: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- members: integer (nullable = true)\n",
      " |-- japanese_title: string (nullable = true)\n",
      " |-- aired: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- aired_from: string (nullable = true)\n",
      " |-- aired_to: integer (nullable = true)\n",
      " |-- ave_rating_minmax: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_result_df = rating_scaled_df.select(['anime_id', 'ave_rating_minmax'])\n",
    "result_df = anime_df.join(rating_result_df, on='anime_id')\n",
    "result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "|anime_id|                name|               genre| type|episodes|rating|members|                   japanese_title|               aired|           image_url|aired_from|  aired_to|ave_rating_minmax|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "|   24171|     Mushibugyou OVA|Action, Fantasy, ...|  OVA|       3|   7.2|   3636|          ムシブギョー 虫奉行 OVA|Jul 18, 2014 to J...|https://cdn.myani...|1405612800|1421337600|       0.70962965|\n",
      "|    9465|Break Blade 4: Sa...|Action, Fantasy, ...|Movie|       1|  7.99|  41598|ブレイク ブレイド 第四章 惨禍ノ地|        Oct 30, 2010|https://cdn.myani...|1288368000|1288368000|        0.7887058|\n",
      "|   17679|               Gambo|  Demons, Historical|Movie|       1|  6.78|   4232|                            GAMBO|        Jul 20, 2013|https://cdn.myani...|1374249600|1374249600|        0.6992337|\n",
      "|    1829|          Gedo Senki|Adventure, Fantas...|Movie|       1|  7.18|  59243|                         ゲド戦記|        Jul 29, 2006|https://cdn.myani...|1154102400|1154102400|       0.70463973|\n",
      "|    8086|Densetsu no Yuush...|Action, Adventure...|   TV|      24|  7.83| 130689|                 伝説の勇者の伝説|Jul 2, 2010 to De...|https://cdn.myani...|1278000000|1292515200|       0.77100796|\n",
      "|   17389|  Kingdom 2nd Season|Action, Historica...|   TV|      39|  8.57|  31234|           キングダム 第2シリーズ|Jun 8, 2013 to Ma...|https://cdn.myani...|1370620800|1393689600|       0.84464884|\n",
      "|   22097|Magi: Sinbad no B...|Action, Adventure...|  OVA|       5|  8.06|  52351|          マギ シンドバッドの冒険|May 14, 2014 to J...|https://cdn.myani...|1399996800|1436889600|        0.7923077|\n",
      "|   30654|Ansatsu Kyoushits...|Action, Comedy, S...|   TV|      25|  8.68| 176475|                 暗殺教室　第２期|Jan 8, 2016 to Ju...|https://cdn.myani...|1452182400|1467302400|        0.8541492|\n",
      "|    5300|Zoku Natsume Yuuj...|Drama, Fantasy, S...|   TV|      13|  8.64| 114173|                    続 夏目友人帳|Jan 6, 2009 to Ma...|https://cdn.myani...|1231171200|1238428800|       0.85489005|\n",
      "|    6336|Mobile Suit Gunda...|Action, Drama, Me...|  OVA|       7|   8.4|  42076| 機動戦士ガンダムUC（ユニコーン）|Mar 12, 2010 to J...|https://cdn.myani...|1268323200|1401984000|       0.83310026|\n",
      "+--------+--------------------+--------------------+-----+--------+------+-------+---------------------------------+--------------------+--------------------+----------+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f18d6d85afa27dc79607f207c49cc7922ddaa66e675d81ef99263abf5db2e8cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
